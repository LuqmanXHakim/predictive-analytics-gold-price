# -*- coding: utf-8 -*-
"""predictive_analytics_gold_price.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10JJvb03kgtg7BFTCMzFOqHLydcWexAD6

# **Proyek Machine Learning Terapan**

Proyek Predictive Analysis: **Gold Price**
- Nama: **Luqman Hakim**
- Email: luqmanxhakim22042002@gmail.com
- Id Dicoding:2608610

# Data Loading
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.model_selection import GridSearchCV
from sklearn.preprocessing import MinMaxScaler
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

from google.colab import files
files.upload()  # Pilih file 'kaggle.json' yang telah diunduh

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

"""Dataset yang digunakan adalah [Gold Price Prediction](https://www.kaggle.com/datasets/altruistdelhite04/gold-price-data) yang diambil dari platform Kaggle. File yang digunakan berupa file csv, yaitu `gld_price_data.csv`."""

!kaggle datasets download -d altruistdelhite04/gold-price-data

!unzip gold-price-data.zip

"""## Menampilkan Isi Dataset"""

df = pd.read_csv('/content/gld_price_data.csv')
df

"""# Exploratory Data Analysis (EDA)

Exploratory data analysis (EDA) merupakan proses investigasi awal pada data untuk menganalisis karakteristik, menemukan pola, anomali, dan memeriksa asumsi pada data.

## Deskripsi Variabel

Pengecekan informasi variabel dari dataset yaitu jumlah kolom, nama kolom, jumlah data per kolom dan tipe datanya.
"""

#menampilan info lebih rinci pada dataframe
df.info()

"""Berdasarkan output di atas, terdapat 1 kolom dengan tipe data object, 5 kolom dengan tipe data float64."""

#menampilkan jumlah baris dan kolom pada dataframe
df.shape

"""## Deskripsi Statistik"""

#menampilkan statistik deskriptif dari data frame
df.describe()

"""Berdasarkan output diatas, didapatkan deskripsi statistik yaitu :
1. count : Jumlah sampel data
2. mean : Nilai rata-rata
3. std : Standar deviasi
4. min : Nilai minimum
5. 25% : Kuartil bawah/Q1
6. 50% : Kuartil tengah/Q2/median
7. 75% : Kuartil atas/Q3
8. max : Nilai maksimum
"""

#visualisasi pairplot
sns.pairplot(df[['SPX','SLV','USO', 'GLD', 'EUR/USD']], plot_kws={"s": 5})

"""Berdasarkan grafik histogram yang berada pada diagonal utama pairplot, dapat disimpulkan sebagai berikut:

- Distribusi Harga Bervariasi: Setiap aset (SPX, SLV, USO, GLD, EUR/USD) memiliki pola distribusi harga yang unik, menunjukkan bahwa harga masing-masing aset cenderung berada pada rentang nilai yang berbeda-beda.
- Puncak Konsentrasi: Beberapa aset menunjukkan satu atau lebih puncak (mode) pada histogramnya, mengindikasikan bahwa harga aset tersebut seringkali terkonsentrasi di sekitar nilai-nilai tertentu.
- Tidak Semua Distribusi Normal: Distribusi harga tidak selalu simetris atau menyerupai kurva normal; ada yang cenderung miring (skewed) atau memiliki beberapa puncak.
"""

#ubah kolom 'Date' menjadi datetime dan ekstrak hari, bulan, tahun
df = (
    df
    .assign(Date=pd.to_datetime(df['Date']))
    .assign(
        Day=lambda x: x['Date'].dt.day,
        Month=lambda x: x['Date'].dt.month,
        Year=lambda x: x['Date'].dt.year
    )
    .drop(columns='Date')
    .loc[:, ['Day', 'Month', 'Year', 'SPX', 'GLD', 'USO', 'SLV', 'EUR/USD']]
)
df

#menghitung rata-rata GolD per tahun
years = df['Year'].unique()
average_prices = []

for year in sorted(years):
    mean_price = df[df['Year'] == year]['GLD'].mean()
    average_prices.append({'Year': year, 'GLD': mean_price})

average_prices_per_year = pd.DataFrame(average_prices)
average_prices_per_year

#menampilkan missing value
df.isna().sum()

#menampilkan duplikat data
df.duplicated().sum()

#menampilkan outliers
desc = df['GLD'].describe()
iqr = desc['75%'] - desc['25%']
lower_bound = desc['25%'] - 1.5 * iqr
upper_bound = desc['75%'] + 1.5 * iqr

outliers1 = df.query("GLD < @lower_bound")
outliers2 = df.query("GLD > @upper_bound")

print(outliers1)
print(outliers2)

#menangani outliers
median_value = df['GLD'].median()
df['GLD'] = df['GLD'].apply(
    lambda x: median_value if x < lower_bound or x > upper_bound else x
)

print(df)

"""## Memisahkan fitur dan target"""

y = df.loc[:, 'GLD']
X = df.drop(columns=y.name)
X = X.drop(['Day', 'Month', 'Year'], axis=1)

"""## Train test split"""

data_split = train_test_split(X, y, test_size=0.2, random_state=2)
X_train, X_test, y_train, y_test = data_split

"""## Normalisasi Data"""

scaler = MinMaxScaler()
X_train_scaled = scaler.fit(X_train).transform(X_train)
X_test_scaled = scaler.transform(X_test)

print(X_train_scaled[:5])
print(X_test_scaled[:5])

"""# Modelling

## Model Linear Regression
"""

from sklearn.linear_model import LinearRegression
lin_reg = LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, positive=False)

lin_reg.fit(X_train, y_train)

param_grid = {'copy_X': [True, False],
              'fit_intercept': [True, False],
              'n_jobs': [None],
              'positive': [True, False]}

grid_search = GridSearchCV(lin_reg,
                           param_grid,
                           cv=5,
                           scoring='neg_mean_squared_error')

grid_search.fit(X, y)

best_params = grid_search.best_params_
best_score = grid_search.best_score_

print("Parameter terbaik untuk model Linear Regression adalah:", best_params)
print("Skor Mean Squared Error (MSE) terbaik untuk model Regresi Linear adalah:", best_score)

"""## Model Random Forest"""

from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import GridSearchCV

rf = RandomForestRegressor()

rf.fit(X_train, y_train)

param_grid = {
    'n_estimators': [50, 100],
    'max_depth': [None, 10, 20],
    'min_samples_split': [2, 5],
    'min_samples_leaf': [1, 2],
    'bootstrap': [True, False]
}

grid_search = GridSearchCV(rf,
                           param_grid,
                           cv=5,
                           scoring='neg_mean_squared_error')

grid_search.fit(X, y)

best_params = grid_search.best_params_
best_score = grid_search.best_score_

print("Parameter terbaik untuk model Random Forest Regressor adalah:", best_params)
print("Skor Mean Squared Error (MSE) terbaik untuk model Random Forest Regression adalah:", best_score)

"""# Evaluasi"""

metrics = pd.DataFrame(index=['Linear Regression','Random Forest Regressor'])

models = {'Linear Regression': lin_reg, 'Random Forest Regressor': rf}

for name, model in models.items():
    mae_train = mean_absolute_error(y_true=y_train, y_pred=model.predict(X_train))
    mae_test = mean_absolute_error(y_true=y_test, y_pred=model.predict(X_test))

    mse_train = mean_squared_error(y_true=y_train, y_pred=model.predict(X_train))
    mse_test = mean_squared_error(y_true=y_test, y_pred=model.predict(X_test))

    r2_train = r2_score(y_true=y_train, y_pred=model.predict(X_train))
    r2_test = r2_score(y_true=y_test, y_pred=model.predict(X_test))

    metrics.loc[name, 'MAE Train'] = round(mae_train, 3)
    metrics.loc[name, 'MAE Test'] = round(mae_test, 3)
    metrics.loc[name, 'MSE Train'] = round(mse_train, 3)
    metrics.loc[name, 'MSE Test'] = round(mse_test, 3)
    metrics.loc[name, 'R2 Train'] = round(r2_train, 3)
    metrics.loc[name, 'R2 Test'] = round(r2_test, 3)

display(metrics)

fig, axes = plt.subplots(2, 3, figsize=(18, 6))
colors = {'Linear Regression': 'blue', 'Random Forest Regressor': 'green'}

metrics_columns = ['MAE Train', 'MSE Train', 'R2 Train', 'MAE Test', 'MSE Test', 'R2 Test']
titles = ['MAE Train', 'MSE Train', 'R2 Train', 'MAE Test', 'MSE Test', 'R2 Test']

for i, ax in enumerate(axes.flatten()):
    ax.bar(metrics.index, metrics[metrics_columns[i]].values,
           color=[colors.get(name, 'gray') for name in metrics.index])
    ax.set_title(titles[i] + ' (Linear Regression vs Random Forest)')
    ax.set_ylabel(titles[i])

plt.tight_layout()
plt.show()

"""
Berdasarkan grafik di atas, dapat disimpulkan yaitu:

- Model Random Forest Regressor Unggul Secara Signifikan: Pada semua metrik evaluasi (MAE, MSE, dan R2) baik pada data latih (Train) maupun data uji (Test), model Random Forest Regressor (batang hijau) secara konsisten menunjukkan kinerja yang jauh lebih baik dibandingkan dengan model Linear Regression (batang biru).

  - MAE dan MSE (Semakin Rendah Semakin Baik): Nilai MAE (Mean Absolute Error) dan MSE (Mean Squared Error) untuk Random Forest Regressor jauh lebih rendah dibandingkan Linear Regression, menunjukkan bahwa prediksi Random Forest memiliki kesalahan yang lebih kecil dan lebih akurat.
  - R2 (Semakin Tinggi Semakin Baik): Nilai R2 (Coefficient of Determination) untuk Random Forest Regressor mendekati 1 (sangat tinggi), sementara Linear Regression jauh lebih rendah. Ini berarti Random Forest Regressor mampu menjelaskan variabilitas data jauh lebih baik daripada Linear Regression.
- Linear Regression Memiliki Kinerja yang Buruk: Model Linear Regression menunjukkan nilai MAE dan MSE yang sangat tinggi serta nilai R2 yang rendah, mengindikasikan bahwa model ini kurang efektif dalam memprediksi data ini.

- Generalisasi Model Random Forest Lebih Baik: Perbedaan kinerja antara data latih dan data uji untuk Random Forest Regressor relatif kecil, menunjukkan bahwa model ini mampu menggeneralisasi dengan baik pada data yang belum pernah dilihat sebelumnya (data uji) dan tidak mengalami overfitting yang parah. Sebaliknya, Linear Regression menunjukkan kinerja yang buruk di kedua set data."""

pred = X_test.iloc[:1].copy()
pred_dict = {'y_true':y_test[:1]}
for name, model in models.items():
    pred_dict[name] = model.predict(pred).round(3)

pd.DataFrame(pred_dict)

"""Berdasarkan output tabel di atas dapat dilihat bahwa urutan algoritma yang paling mendekati dengan nilai y_true adalah Random Forest. Nilai y_true sebesar 120.580002 dan nilai prediksi Random Forest sebesar 130.717."""